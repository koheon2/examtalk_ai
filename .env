# LLM
LLM_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
MAX_NEW_TOKENS=180
TEMPERATURE=0.4
TOP_P=0.9
HF_TOKEN = YOUR_HF_TOKEN

# Embedding
EMB_MODEL=intfloat/multilingual-e5-base

# Input caps (안정성 위해 권장)
MAX_REVIEWS=50
MAX_REVIEW_CHARS=400
MAX_TOTAL_CHARS=12000

# Concurrency (LLM은 무조건 제한)
LLM_MAX_CONCURRENCY=1

HOST=0.0.0.0
PORT=80
